#########################################################
# Configuration parameters for the docker project       #
# Change the variables below to your need:              #
#########################################################
DOCKER_PROJECT_NAME=${PROJECT_NAME:-"ollama"}             # The name of the Docker project
IMAGE_VARIANT=${APP_VARIANT:-"app"}                       # The variant of the Docker image.
IMAGE_TAG="${IMAGE_VERSION}-${IMAGE_VARIANT}"             # The tag of the Docker image
IMAGE_NAME="ghcr.io/entelecheia/ollama"                   # The full name of the Docker image
BASE_VARIANT=${BASE_VARIANT:-"base"}                      # The variant of the Docker image.
BUILD_FROM="nvcr.io/nvidia/cuda:11.8.0-devel-ubuntu22.04" # The base image for the Docker build

CONTAINER_NAME="${DOCKER_PROJECT_NAME}-${PROJECT_ID}"     # The hostname of the Docker container
CONTAINER_HOSTNAME="${DOCKER_PROJECT_NAME}-server"        # The hostname of the Docker container
CONTAINER_HF_TOKEN=${HF_TOKEN:-""}                        # The Hugging Face token to use in the container
CONTAINER_WEB_SVC_PORT=${WEB_SVC_PORT:-"11434"}           # The Web service port in the Docker container
HOST_WEB_SVC_PORT=${HOST_WEB_SVC_PORT-"11434"}            # The Web service port on the host machine to be mapped to the container's Web service port
CONTAINER_IPC=${CONTAINER_IPC:-"host"}                    # The IPC mode for the Docker container
CONTAINER_CUDA_DEVICE_ID=${CONTAINER_CUDA_DEVICE_ID:-"2"} # The ID of the CUDA device to use, e.g. all, 0, 1, 2, etc.

CONTAINER_OLLAMA_DIR="${CONTAINER_HOME}/.ollama"
CONTAINER_OLLAMA_MODELS="${CONTAINER_OLLAMA_DIR}/models"
HOST_OLLAMA_DIR="$PWD/workspace"
HOST_OLLAMA_MODELS="$HOST_OLLAMA_DIR/models"
