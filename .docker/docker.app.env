#########################################################
# Configuration parameters for the docker project       #
# Change the variables below to your need:              #
#########################################################
OLLAMA_MODEL_NAME=${OLLAMA_MODEL_NAME:-"mistralai/Mistral-7B-Instruct-v0.1"} # The ID of the model to use

CONTAINER_OLLAMA_DIR="${CONTAINER_HOME}/.ollama"
CONTAINER_OLLAMA_MODELS="${CONTAINER_OLLAMA_DIR}/models"
HOST_OLLAMA_DIR="$PWD/workspace"
HOST_OLLAMA_MODELS="$HOST_OLLAMA_DIR/models"

#######################################################################################
# Please do not make any changes below this line if you don't know what you are doing #
# change the variables above to your need                                             #
#######################################################################################
# docker build: Configuration parameters for building the Docker image
IMAGE_VARIANT=${IMAGE_VARIANT:-"app"}                                        # The variant of the Docker image.
IMAGE_TAG="${IMAGE_VERSION}-${IMAGE_VARIANT}"                                # The tag of the Docker image
IMAGE_NAME="${CONTAINER_REGISTRY}/${DOCKER_USERNAME}/${DOCKER_PROJECT_NAME}" # The full name of the Docker image
BUILD_FROM="nvcr.io/nvidia/cuda:11.8.0-devel-ubuntu22.04"                    # The base image for the Docker build

# docker run: Configuration parameters for running the Docker container
CONTAINER_LAUNCH_SCRIPT="${CONTAINER_WORKSPACE_ROOT}/scripts/launch.sh" # The name of the launch script
CONTAINER_CUDA_DEVICE_ID=${OLLAMA_CUDA_DEVICE_ID:-"all"}                # The ID of the CUDA device to use, e.g. all, 0, 1, 2, etc.

CONTAINER_SERVICE_NAME=${OLLAMA_SERVICE_NAME:-"app"}  # The server name (optional, can be left empty)
CONTAINER_WEB_SVC_PORT=${WEB_SVC_PORT:-"11434"}       # The Web service port in the Docker container
HOST_WEB_SVC_PORT=${HOST_WEB_SVC_PORT-"11434"} # The Web service port on the host machine to be mapped to the container's Web service port
